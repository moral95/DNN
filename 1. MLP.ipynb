{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 라이브러리 설정\n",
    "2. GPU 설정\n",
    "3. HYPER PARAMETER 설정\n",
    "4. DATA 준비\n",
    "5. 모델 설계\n",
    "6. 모델 훈련\n",
    "7. 모델 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 라이브러리 설정\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# optimizer 부르기\n",
    "from torchvision import datasets, transforms\n",
    "# 전처리 단계 - transform(데이터 변환), datasets(데이터 부르기)\n",
    "import matplotlib.pyplot as plt\n",
    "# 그림 및 그래프 출력 방법\n",
    "from torch.utils.data import DataLoader\n",
    "# torch.utils.data에 저장된 dataloader 부르기 \n",
    "from tqdm.notebook import tqdm\n",
    "# 진행도를 확인하기 위해서 부르는 기능. 일반적으로 epoch에 사용되나, 다양한 상황의 진행상황을 보기 위해서 사용함.\n",
    "# epoch 진행 상태 외적으로 사용하는 것은 잘 모름(물론 상황에 맞춰 사용하겠지만, 코드에 맞추어 구현 방법 잘 모름)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. GPU 설정( 단일 )\n",
    "Device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "# 2-1. GPU 병렬 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0461,  0.4024, -1.0115]])\n",
      "tensor([[ 0.2167, -0.6123]])\n",
      "tensor([[0.5036]])\n",
      "tensor([], size=(1, 0))\n",
      "tensor([], size=(0, 3))\n",
      "tensor([[ 0.2310,  0.6931, -0.2669],\n",
      "        [ 2.1785,  0.1021, -0.2590]])\n",
      "tensor([[-0.1549, -1.3706, -0.1319,  0.8848],\n",
      "        [-0.2611,  0.6104, -0.0098, -1.4473]])\n"
     ]
    }
   ],
   "source": [
    "# 3. HyperParameter\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "lr = 1e-4\n",
    "n_class = 10\n",
    "\n",
    "# seed (고정)\n",
    "random_seed = 1234\n",
    "torch.manual_seed(random_seed)\n",
    "print(torch.randn(1,3))\n",
    "print(torch.randn(1,2))\n",
    "print(torch.randn(1,1))\n",
    "print(torch.randn(1,0))\n",
    "print(torch.randn(0,3))\n",
    "print(torch.randn(2,3))\n",
    "print(torch.randn(2,4))\n",
    "# tensor 행렬을 랜덤으로 어느 정도 사이즈로 뽑는 지 본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 전처리 ( 데이터를 다운 받고, 변환합니다. )\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transforms.ToTensor())\n",
    "# 위의 라이브러리를 보면 torchvision을 에서 datasets을 가져온다는 것을 알 수 있다. 그 datasets 중에서 MNIST 데이터를 가져온다는 것임.\n",
    "# 구글에 torchvison 라이브러리 뒤져보면, 불러올 수 있는 각 데이터셋 종류와 작성법에 대해 써져 있음.\n",
    "# 일반적으로 transform은 tranform 변수를 지정해서 다양한 list을 작성하는데, 이때 argumentation을 추가한다.\n",
    "# 여기서는 꼭 필요한 image를 ToTensor만 작성하였다. 아마 데이터셋이 이미지로 저장되어 있을 텐데, 이를 Tensor 형식으로 변환한다는 뜻이다.\n",
    "# 이를 train/test_dataset의 변수로 지정하였습니다.\n",
    "sample_data, label = train_dataset[0]\n",
    "# 샘플 데이터와 레이블을 분할. train_dataset은 그렇게 구성된 것으로 보임\n",
    "\n",
    "plt.imshow(sample_data.reshape((28,28)), cmap='gray')\n",
    "# plt.imshow(sample_data.reshape((28,28)), cmap='CMRmap')\n",
    "# plt.imshow(sample_data.reshape((32,32)), cmap='gray')\n",
    "# 이미지는 784이기때문에 다른 숫자를 입히면 출력이 되지 않는다. \n",
    "# 똑같은 명령어를 부르면 최하단의 명령어만 입힌다.\n",
    "# cmap로 다양한 색상을 부를 수 있지만, 단지 Classification이라면 색상 feature 찾기는 의미가 없다. 우리가 보고 싶은건 단지 검은 배경 숫자 확인이니까.\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] train : 60000, test : 10000\n",
      "[DataLoader] train : 938, test : 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 loder (전처리된 데이터셋을 배치사이즈로 자르고, 섞는 등의 작업을 하는 변수를 지정합니다. )\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle= False)\n",
    "\n",
    "# DataLoader(dataset, batch_size=1, shuffle=False, sampler=None,\n",
    "#            batch_sampler=None, num_workers=0, collate_fn=None,\n",
    "#            pin_memory=False, drop_last=False, timeout=0,\n",
    "#            worker_init_fn=None, *, prefetch_factor=2,\n",
    "#            persistent_workers=False)\n",
    "# 위는 torch.utils.data 안의 DataLoader 이다. 인터넷 찾아보면 바로 나온다.\n",
    "# 또한 위는 3개의 변수만을 사용합니다.\n",
    "# ??? 각 내용은 뭘 뜻하는지 제대로 뒤져보면 알겠지만, 지금은 모름. num_workers= gpu 안에 있는 연산자 개수인거 같은데...\n",
    "# ??? 몇 개인지, 어디서 확인하는 지 알 수 없음.\n",
    "\n",
    "print(f\"[Dataset] train : {len(train_dataset)}, test : {len(test_dataset)}\")\n",
    "# 데이터 셋의 개수를 알려준다.\n",
    "print(f\"[DataLoader] train : {len(train_dataloader)}, test : {len(test_dataloader)}\")\n",
    "# 데이터 로더 프린트인데... 배치가 64크기 이니 1 배치당 64개가 들어가서, 개수 = 데이터셋 전체 개수/(배치개수) 로 구성되어 있는 것을 출력\n",
    "# f 로 아마 전체 \"\" 안을 출력이 가능하는 것으로 본다. 그 안에 {}는 해당 안의 내용만 문자가 아닌 시스템 작동을 하는 것으로 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear1): Linear(in_features=784, out_features=784, bias=True)\n",
      "  (linear2): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (linear3): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (linear4): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (linear5): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (linear6): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (linear7): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (classifier_layer): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "<class '__main__.MLP'>\n"
     ]
    }
   ],
   "source": [
    "# 모델 구현\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1= nn.Linear(784,784)\n",
    "        self.linear2= nn.Linear(784,512)\n",
    "        self.linear3= nn.Linear(512,256)\n",
    "        self.linear4= nn.Linear(256,256)\n",
    "        self.linear5= nn.Linear(256,256)\n",
    "        self.linear6= nn.Linear(256,256)\n",
    "        self.linear7= nn.Linear(256,256)\n",
    "        self.classifier_layer = nn.Linear(256, n_class)\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "# 8개의 linear 세움.\n",
    "# nn의 기능ㅇ르 사용하여 linear를 세우고, 시작 노드 개수, 끝 노드 개수 선정.\n",
    "# 중요한 것은 각 linear 시작과 끝이 같아야한다.\n",
    "# Classifier인 8번째의 linear는 256개에서 n_class(10개)로 줄어들게 설정\n",
    "# 마지막 softmax로 각 이미지에 대해 0~1 사이의 점수를 준다.\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1, 784)\n",
    "        # print(x.view(2,784))\n",
    "        x = torch.sigmoid(self.linear1(x))\n",
    "        x = torch.sigmoid(self.linear2(x))\n",
    "        x = torch.sigmoid(self.linear3(x))\n",
    "        x = torch.sigmoid(self.linear4(x))\n",
    "        x = torch.sigmoid(self.linear5(x))\n",
    "        x = torch.sigmoid(self.linear6(x))\n",
    "        x = torch.sigmoid(self.linear7(x))\n",
    "\n",
    "        output = self.classifier_layer(x)\n",
    "        return self.softmax(output)\n",
    "# 일반적으로 우리는 linear 후 활성화 함수(sigmoid 등)을 작성해서 보여주지만, 코드 작성에는 class로 주어줬기 때문에 다르게 정의\n",
    "# init 으로 linear, classifier, softmax를 self 방식으로 내가 정의 하고 싶은대로 정의했다. \n",
    "# clas 안에 foward라는 함수안에 torch.sigmoid 정의된 기능으로 사용하여 x를 지정하였다.\n",
    "# x.vew(-1)는 왜 했는지 모르겠다.\n",
    "\n",
    "# 모델 불러오기\n",
    "model = MLP(n_class).to(Device)\n",
    "# MLP 안에 n_class(임의 이름, 다른걸로 담아도 됨)를 지정하였기 때문에, n_class를 넣었다. classification 데이터셋의 숫자를 직접 넣어도 된다.(하지만 번거러우니 그냥 변수를 저장하고 쓰자.)\n",
    "print(model)\n",
    "print(MLP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============[EPOCHS] 1/10 =============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f887b129152c47a6b18af7f50d6dd465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  1.628466\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112d2f7e117845b09c6296db59f9cc66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  1.633242\n",
      "[Test RESULT]  82.780%\n",
      "============[EPOCHS] 2/10 =============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873f1d4dce134770b68fe303557b7a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  3.256529\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435eb7140df34f169cf8ecc05163e0a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  3.270171\n",
      "[Test RESULT]  82.440%\n",
      "============[EPOCHS] 3/10 =============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f36feb1cfe4c7db559d85aee278de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  4.883299\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce2f60ef352437b80b74e649fd36ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  4.907192\n",
      "[Test RESULT]  82.430%\n",
      "============[EPOCHS] 4/10 =============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be661674d64c447bb6491e5ac5727a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  6.507881\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580bb7e18e8e4ce89c4cd2b0eaa487b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  6.541271\n",
      "[Test RESULT]  82.700%\n",
      "============[EPOCHS] 5/10 =============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c7c35945ea4fa480345287f755e349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  8.132634\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9419bab135cc4898bb10c5fbd90f5fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  8.176821\n",
      "[Test RESULT]  82.500%\n",
      "============[EPOCHS] 6/10 =============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04eb67315d80432c951b58f10d17fac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  9.756865\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e95184846041bf9f0e716bd85ad40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  9.810587\n",
      "[Test RESULT]  82.750%\n",
      "============[EPOCHS] 7/10 =============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ab88e866494ef8974839c7561f61d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  11.381239\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72deddeb381f4032a2f8eb6c610d8533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  11.445903\n",
      "[Test RESULT]  82.540%\n",
      "============[EPOCHS] 8/10 =============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b94f8a4fce4c638dd17b81fbcf681c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  13.005090\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32baf30a10c445cbe90e995f091d3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  13.077253\n",
      "[Test RESULT]  82.990%\n",
      "============[EPOCHS] 9/10 =============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46bb4427feb48f1a032a15497506c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  14.628103\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983f0ff166cd4546abb32ecf8dfef913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  14.706509\n",
      "[Test RESULT]  83.180%\n",
      "============[EPOCHS] 10/10 =============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5693a62a29554df4a073987980d7d1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  16.249914\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a998000851c94a9d88ae59092054201d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  16.336458\n",
      "[Test RESULT]  83.090%\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련, 검증\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_loss = 0.0\n",
    "test_loss = 0.0\n",
    "epoch_train_loss = []\n",
    "epoch_test_loss = []\n",
    "# epoch_train/test_loss를 리스트 []형식으로 지정하였다. 마지막에 append로 train_loss/len(train_dataloader)를 넣었습니다.\n",
    "for e in range(1, num_epochs+1 ):\n",
    "    print(f\"============[EPOCHS] {e}/{num_epochs} =============\")\n",
    "# train/test_loss를 사용하려 하면 먼저 정의를 해줘야하기에 loss를 0으로 만들었다.\n",
    "\n",
    "    #train\n",
    "    model.train()\n",
    "    for data, label in tqdm(train_dataloader):\n",
    "        data = data.to(Device)\n",
    "        label = label.to(Device)\n",
    "        output = model (data)\n",
    "        loss = loss_func(output, label)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    epoch_train_loss.append(train_loss/len(train_dataloader))\n",
    "    print(f\"Train Loss: {train_loss/len(train_dataloader): .6f}\")\n",
    "# data(image.Tensor), label를 device에 넣는다.\n",
    "# loss_func(nn.Crossentropyloss)에 output(예측), label(정답, target) 두개를 넣어서 값을 출력한다.\n",
    "# nn.CrossLoss 안의 item을 추출해서 넣는다.( 정확히 뭐를 뽑는 지는 모르겠음 ), 매 에폭마다 더해서 넣어줌.\n",
    "# optimzer를 일단 zero_grad써서 초기화를 하여 주어서 매 에폭마다 훈련시킨다.\n",
    "# nn.CrossLoss 안의 backward 기능(함수)를 가져와서 진행한다.\n",
    "# ???. optimizer(Adam)의 기능 step을 사용하여서 진행한다. (근데 step이 뭐지?)\n",
    "\n",
    "    with torch.no_grad(): # autograd 엔진 비활성화\n",
    "        model.eval() # dropout 비활성화 시켜줌\n",
    "        test_acc = 0.0\n",
    "        for data, label in tqdm(test_dataloader):\n",
    "            data = data.to(Device)\n",
    "            label = label.to(Device)\n",
    "            output = model(data)\n",
    "            loss = loss_func(output, label)\n",
    "            test_loss += loss.item()\n",
    "            preds = torch.argmax(output, dim=1)\n",
    "            test_acc += preds.eq(label).sum()\n",
    "    epoch_test_loss.append(test_loss/len(test_dataloader))\n",
    "    print(f\"Test Loss: {test_loss/len(test_dataloader) : .6f}\")\n",
    "    print(f\"[Test RESULT] {(test_acc/len(test_dataloader))*100: .3f}%\")\n",
    "# torch.no_grad는 더이상 grad 는 하지 않는 것.\n",
    "# preds= argmax(output, dim=1), argmax는 나온 결과 중 최대값 1개를 찾는 건데, 최대값이 몇번째인지를 찾는 것이다. dim=1은 1개로 나오는 거 일...듯하다\n",
    "# test acc는 preds의 label의 위치가 같다면 그 개수를 더하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_train_loss, 'b')\n",
    "plt.plot(epoch_test_loss,'r')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NewG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
